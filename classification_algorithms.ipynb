{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPe2x7sP1RE68HD/qfXT/7l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nazimulrahmann/machine_learning/blob/main/classification_algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "uuMYafI6dV_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dummy Dataset**"
      ],
      "metadata": {
        "id": "kyG4uA5ccdyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Parameters\n",
        "n_samples = 1000  # Total number of samples\n",
        "n_features = 5    # Number of features\n",
        "n_classes = 3     # Number of classes\n",
        "\n",
        "# Generate random features (X)\n",
        "# Using normal distribution with different means for each class\n",
        "X = np.zeros((n_samples, n_features))\n",
        "y = np.zeros(n_samples, dtype=int)\n",
        "\n",
        "# Create class clusters with different characteristics\n",
        "for class_idx in range(n_classes):\n",
        "    # Select indices for this class\n",
        "    start_idx = class_idx * (n_samples // n_classes)\n",
        "    end_idx = (class_idx + 1) * (n_samples // n_classes)\n",
        "    if class_idx == n_classes - 1:  # Handle last class in case n_samples isn't divisible\n",
        "        end_idx = n_samples\n",
        "\n",
        "    # Generate features with class-specific mean and variance\n",
        "    X[start_idx:end_idx] = np.random.normal(\n",
        "        loc=class_idx * 2,  # Mean increases with class index\n",
        "        scale=1.0 + class_idx * 0.5,  # Variance increases with class index\n",
        "        size=(end_idx - start_idx, n_features)\n",
        "    )\n",
        "\n",
        "    # Assign class labels\n",
        "    y[start_idx:end_idx] = class_idx\n",
        "\n",
        "# Add some noise to make it more realistic\n",
        "X += np.random.normal(scale=0.5, size=X.shape)\n",
        "\n",
        "# Split into training and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y  # Preserve class distribution in split\n",
        ")"
      ],
      "metadata": {
        "id": "4N4bcr7GcYpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**"
      ],
      "metadata": {
        "id": "-NyP_oH1c6OK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Evaluate a model and print metrics\n",
        "    Returns a dictionary of metrics\n",
        "    \"\"\"\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(pd.DataFrame(report).transpose())\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    return {\n",
        "        'model': str(model),\n",
        "        'accuracy': accuracy,\n",
        "        'classification_report': report,\n",
        "        'confusion_matrix': cm\n",
        "    }"
      ],
      "metadata": {
        "id": "0nCgD0k2c2uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression | Classification**"
      ],
      "metadata": {
        "id": "SyScqsqycm2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Model setup\n",
        "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# Parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', None],\n",
        "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "    'class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "# Grid search\n",
        "print(\"Training Logistic Regression...\")\n",
        "log_reg_grid = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "log_reg_grid.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_log_reg = log_reg_grid.best_estimator_\n",
        "print(f\"Best parameters: {log_reg_grid.best_params_}\")\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\nEvaluating Logistic Regression:\")\n",
        "log_reg_metrics = evaluate_model(best_log_reg, X_test, y_test)"
      ],
      "metadata": {
        "id": "KpBWsXa5cY5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ridge Classifier**"
      ],
      "metadata": {
        "id": "JCuvIUR2dI-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import RidgeClassifier\n",
        "\n",
        "ridge = RidgeClassifier(random_state=42)\n",
        "param_grid = {'alpha': [0.1, 0.5, 1.0, 2.0, 5.0]}\n",
        "\n",
        "print(\"Training Ridge Classifier...\")\n",
        "ridge_grid = GridSearchCV(ridge, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "ridge_grid.fit(X_train, y_train)\n",
        "\n",
        "best_ridge = ridge_grid.best_estimator_\n",
        "print(f\"Best parameters: {ridge_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating Ridge Classifier:\")\n",
        "ridge_metrics = evaluate_model(best_ridge, X_test, y_test)"
      ],
      "metadata": {
        "id": "r5BUIUcVdDk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SGD Classifier**"
      ],
      "metadata": {
        "id": "4Jz3Ru5ndpOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd = SGDClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'loss': ['hinge', 'log_loss', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
        "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
        "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
        "    'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
        "    'class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "print(\"Training SGD Classifier...\")\n",
        "sgd_grid = GridSearchCV(sgd, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "sgd_grid.fit(X_train, y_train)\n",
        "\n",
        "best_sgd = sgd_grid.best_estimator_\n",
        "print(f\"Best parameters: {sgd_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating SGD Classifier:\")\n",
        "sgd_metrics = evaluate_model(best_sgd, X_test, y_test)"
      ],
      "metadata": {
        "id": "FWRYiI2RdmBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree Classifier**"
      ],
      "metadata": {
        "id": "CbfhlxetdxNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
        "    'max_depth': [None, 5, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "print(\"Training Decision Tree...\")\n",
        "dt_grid = GridSearchCV(dt, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "dt_grid.fit(X_train, y_train)\n",
        "\n",
        "best_dt = dt_grid.best_estimator_\n",
        "print(f\"Best parameters: {dt_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating Decision Tree:\")\n",
        "dt_metrics = evaluate_model(best_dt, X_test, y_test)"
      ],
      "metadata": {
        "id": "YRvYNiKpdt0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Classifier**"
      ],
      "metadata": {
        "id": "YZG2eqKYd4Fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'bootstrap': [True, False],\n",
        "    'class_weight': [None, 'balanced', 'balanced_subsample']\n",
        "}\n",
        "\n",
        "print(\"Training Random Forest...\")\n",
        "rf_grid = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "rf_grid.fit(X_train, y_train)\n",
        "\n",
        "best_rf = rf_grid.best_estimator_\n",
        "print(f\"Best parameters: {rf_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating Random Forest:\")\n",
        "rf_metrics = evaluate_model(best_rf, X_test, y_test)"
      ],
      "metadata": {
        "id": "5pIJuhXxd1a_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extra Tree Classifier**"
      ],
      "metadata": {
        "id": "CNgUGtwsd-Y9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "et = ExtraTreesClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'class_weight': [None, 'balanced', 'balanced_subsample']\n",
        "}\n",
        "\n",
        "print(\"Training Extra Trees...\")\n",
        "et_grid = GridSearchCV(et, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "et_grid.fit(X_train, y_train)\n",
        "\n",
        "best_et = et_grid.best_estimator_\n",
        "print(f\"Best parameters: {et_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating Extra Trees:\")\n",
        "et_metrics = evaluate_model(best_et, X_test, y_test)"
      ],
      "metadata": {
        "id": "qJ9hAlEzd65j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Boosting classifier**"
      ],
      "metadata": {
        "id": "ABkcb2WqeGA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "print(\"Training Gradient Boosting...\")\n",
        "gb_grid = GridSearchCV(gb, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "gb_grid.fit(X_train, y_train)\n",
        "\n",
        "best_gb = gb_grid.best_estimator_\n",
        "print(f\"Best parameters: {gb_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating Gradient Boosting:\")\n",
        "gb_metrics = evaluate_model(best_gb, X_test, y_test)"
      ],
      "metadata": {
        "id": "zLCfXEvVeCBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBoost Classifier**"
      ],
      "metadata": {
        "id": "ctC5OLadeNc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = XGBClassifier(random_state=42, eval_metric='logloss', use_label_encoder=False)\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2],\n",
        "    'reg_alpha': [0, 0.1, 1],\n",
        "    'reg_lambda': [0, 0.1, 1],\n",
        "    'scale_pos_weight': [1, 2, 5]\n",
        "}\n",
        "\n",
        "print(\"Training XGBoost...\")\n",
        "xgb_grid = GridSearchCV(xgb, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "xgb_grid.fit(X_train, y_train)\n",
        "\n",
        "best_xgb = xgb_grid.best_estimator_\n",
        "print(f\"Best parameters: {xgb_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating XGBoost:\")\n",
        "xgb_metrics = evaluate_model(best_xgb, X_test, y_test)"
      ],
      "metadata": {
        "id": "mfFTSNddeKg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LGBM Classifier**"
      ],
      "metadata": {
        "id": "Klvq8n9PeUgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgbm = LGBMClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'num_leaves': [31, 63, 127],\n",
        "    'max_depth': [-1, 10, 20],\n",
        "    'min_child_samples': [20, 50],\n",
        "    'reg_alpha': [0, 0.1, 1],\n",
        "    'reg_lambda': [0, 0.1, 1],\n",
        "    'class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "print(\"Training LightGBM...\")\n",
        "lgbm_grid = GridSearchCV(lgbm, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "lgbm_grid.fit(X_train, y_train)\n",
        "\n",
        "best_lgbm = lgbm_grid.best_estimator_\n",
        "print(f\"Best parameters: {lgbm_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating LightGBM:\")\n",
        "lgbm_metrics = evaluate_model(best_lgbm, X_test, y_test)"
      ],
      "metadata": {
        "id": "w1BXIxr6eRap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cat Boost Classifier**"
      ],
      "metadata": {
        "id": "_O6pPm2uebIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "7zHUqSlfeipA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "\n",
        "cb = CatBoostClassifier(random_state=42, verbose=0)\n",
        "param_grid = {\n",
        "    'iterations': [100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'depth': [4, 6, 8],\n",
        "    'l2_leaf_reg': [1, 3, 5],\n",
        "    'auto_class_weights': [None, 'Balanced']\n",
        "}\n",
        "\n",
        "print(\"Training CatBoost...\")\n",
        "cb_grid = GridSearchCV(cb, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "cb_grid.fit(X_train, y_train)\n",
        "\n",
        "best_cb = cb_grid.best_estimator_\n",
        "print(f\"Best parameters: {cb_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating CatBoost:\")\n",
        "cb_metrics = evaluate_model(best_cb, X_test, y_test)"
      ],
      "metadata": {
        "id": "Qf9pnzt4eYiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adaboost Classifier**"
      ],
      "metadata": {
        "id": "deILX0UienBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada = AdaBoostClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 1.0],\n",
        "    'algorithm': ['SAMME', 'SAMME.R']\n",
        "}\n",
        "\n",
        "print(\"Training AdaBoost...\")\n",
        "ada_grid = GridSearchCV(ada, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "ada_grid.fit(X_train, y_train)\n",
        "\n",
        "best_ada = ada_grid.best_estimator_\n",
        "print(f\"Best parameters: {ada_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating AdaBoost:\")\n",
        "ada_metrics = evaluate_model(best_ada, X_test, y_test)"
      ],
      "metadata": {
        "id": "di69eTrleeKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hist Gradient Boosting Classifier**"
      ],
      "metadata": {
        "id": "m3kTEiQSesp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "hgb = HistGradientBoostingClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_iter': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_leaf': [20, 50, 100],\n",
        "    'class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "print(\"Training Hist Gradient Boosting...\")\n",
        "hgb_grid = GridSearchCV(hgb, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "hgb_grid.fit(X_train, y_train)\n",
        "\n",
        "best_hgb = hgb_grid.best_estimator_\n",
        "print(f\"Best parameters: {hgb_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating Hist Gradient Boosting:\")\n",
        "hgb_metrics = evaluate_model(best_hgb, X_test, y_test)"
      ],
      "metadata": {
        "id": "luCwt-dBepn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Suport Vector Classifier**"
      ],
      "metadata": {
        "id": "9rHmntVZezNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc = SVC(random_state=42, probability=True)\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "    'gamma': ['scale', 'auto', 0.1, 1],\n",
        "    'degree': [2, 3, 4],\n",
        "    'class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "print(\"Training SVM...\")\n",
        "svc_grid = GridSearchCV(svc, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "svc_grid.fit(X_train, y_train)\n",
        "\n",
        "best_svc = svc_grid.best_estimator_\n",
        "print(f\"Best parameters: {svc_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating SVM:\")\n",
        "svc_metrics = evaluate_model(best_svc, X_test, y_test)"
      ],
      "metadata": {
        "id": "b-657Yy1ewS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Support Vector Classifier**"
      ],
      "metadata": {
        "id": "isfPXfLbe52z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "linear_svc = LinearSVC(random_state=42)\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'loss': ['hinge', 'squared_hinge'],\n",
        "    'dual': [True, False],\n",
        "    'class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "print(\"Training Linear SVM...\")\n",
        "linear_svc_grid = GridSearchCV(linear_svc, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "linear_svc_grid.fit(X_train, y_train)\n",
        "\n",
        "best_linear_svc = linear_svc_grid.best_estimator_\n",
        "print(f\"Best parameters: {linear_svc_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating Linear SVM:\")\n",
        "linear_svc_metrics = evaluate_model(best_linear_svc, X_test, y_test)"
      ],
      "metadata": {
        "id": "7XV5X6JDe3Us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nu Support Vector Classifier**"
      ],
      "metadata": {
        "id": "y1lGc-fWfFob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import NuSVC\n",
        "\n",
        "nu_svc = NuSVC(random_state=42, probability=True)\n",
        "param_grid = {\n",
        "    'nu': [0.1, 0.5, 0.8],\n",
        "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "    'gamma': ['scale', 'auto', 0.1, 1],\n",
        "    'class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "print(\"Training NuSVC...\")\n",
        "nu_svc_grid = GridSearchCV(nu_svc, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "nu_svc_grid.fit(X_train, y_train)\n",
        "\n",
        "best_nu_svc = nu_svc_grid.best_estimator_\n",
        "print(f\"Best parameters: {nu_svc_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating NuSVC:\")\n",
        "nu_svc_metrics = evaluate_model(best_nu_svc, X_test, y_test)"
      ],
      "metadata": {
        "id": "gInizJB1fA8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gaussian Naive Bayes Classifier**"
      ],
      "metadata": {
        "id": "hK9fJxIyfMZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "param_grid = {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]}\n",
        "\n",
        "print(\"Training Gaussian Naive Bayes...\")\n",
        "gnb_grid = GridSearchCV(gnb, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "gnb_grid.fit(X_train, y_train)\n",
        "\n",
        "best_gnb = gnb_grid.best_estimator_\n",
        "print(f\"Best parameters: {gnb_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating Gaussian Naive Bayes:\")\n",
        "gnb_metrics = evaluate_model(best_gnb, X_test, y_test)"
      ],
      "metadata": {
        "id": "x6-o74gxfJTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bernoulli Naive Bayes**"
      ],
      "metadata": {
        "id": "GvKGHf-kfYt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "bnb = BernoulliNB()\n",
        "param_grid = {\n",
        "    'alpha': [0.1, 0.5, 1.0, 2.0],\n",
        "    'binarize': [None, 0.0, 0.5]\n",
        "}\n",
        "\n",
        "print(\"Training Bernoulli Naive Bayes...\")\n",
        "bnb_grid = GridSearchCV(bnb, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "bnb_grid.fit(X_train, y_train)\n",
        "\n",
        "best_bnb = bnb_grid.best_estimator_\n",
        "print(f\"Best parameters: {bnb_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating Bernoulli Naive Bayes:\")\n",
        "bnb_metrics = evaluate_model(best_bnb, X_test, y_test)"
      ],
      "metadata": {
        "id": "Yvh8nv-KfTdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multinomial Naive Bayes**"
      ],
      "metadata": {
        "id": "Gc2qyq-RffFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "mnb = MultinomialNB()\n",
        "param_grid = {\n",
        "    'alpha': [0.1, 0.5, 1.0, 2.0],\n",
        "    'fit_prior': [True, False]\n",
        "}\n",
        "\n",
        "print(\"Training Multinomial Naive Bayes...\")\n",
        "mnb_grid = GridSearchCV(mnb, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "mnb_grid.fit(X_train, y_train)\n",
        "\n",
        "best_mnb = mnb_grid.best_estimator_\n",
        "print(f\"Best parameters: {mnb_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating Multinomial Naive Bayes:\")\n",
        "mnb_metrics = evaluate_model(best_mnb, X_test, y_test)"
      ],
      "metadata": {
        "id": "W-E7QkSOfd-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Complement Naive Bayes Classification**"
      ],
      "metadata": {
        "id": "PR4Nl-QoflEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import ComplementNB\n",
        "\n",
        "cnb = ComplementNB()\n",
        "param_grid = {\n",
        "    'alpha': [0.1, 0.5, 1.0, 2.0],\n",
        "    'fit_prior': [True, False],\n",
        "    'norm': [True, False]\n",
        "}\n",
        "\n",
        "print(\"Training Complement Naive Bayes...\")\n",
        "cnb_grid = GridSearchCV(cnb, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "cnb_grid.fit(X_train, y_train)\n",
        "\n",
        "best_cnb = cnb_grid.best_estimator_\n",
        "print(f\"Best parameters: {cnb_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating Complement Naive Bayes:\")\n",
        "cnb_metrics = evaluate_model(best_cnb, X_test, y_test)"
      ],
      "metadata": {
        "id": "25a7iuKvfiKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Discriminant Analysis**"
      ],
      "metadata": {
        "id": "MVfSa2Wgfwxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "param_grid = {\n",
        "    'solver': ['svd', 'lsqr', 'eigen'],\n",
        "    'shrinkage': [None, 'auto', 0.1, 0.5, 0.9]\n",
        "}\n",
        "\n",
        "print(\"Training LDA...\")\n",
        "lda_grid = GridSearchCV(lda, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "lda_grid.fit(X_train, y_train)\n",
        "\n",
        "best_lda = lda_grid.best_estimator_\n",
        "print(f\"Best parameters: {lda_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating LDA:\")\n",
        "lda_metrics = evaluate_model(best_lda, X_test, y_test)"
      ],
      "metadata": {
        "id": "ei8kXvbZfrbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quadratic Discriminant Analysis**"
      ],
      "metadata": {
        "id": "h_ToTOtTf43w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "qda = QuadraticDiscriminantAnalysis()\n",
        "param_grid = {'reg_param': [0.0, 0.1, 0.5, 1.0]}\n",
        "\n",
        "print(\"Training QDA...\")\n",
        "qda_grid = GridSearchCV(qda, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "qda_grid.fit(X_train, y_train)\n",
        "\n",
        "best_qda = qda_grid.best_estimator_\n",
        "print(f\"Best parameters: {qda_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating QDA:\")\n",
        "qda_metrics = evaluate_model(best_qda, X_test, y_test)"
      ],
      "metadata": {
        "id": "LgrnbFgpf0Nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN Classifier**"
      ],
      "metadata": {
        "id": "Y5vCeONQf-e0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "    'p': [1, 2]\n",
        "}\n",
        "\n",
        "print(\"Training KNN...\")\n",
        "knn_grid = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "knn_grid.fit(X_train, y_train)\n",
        "\n",
        "best_knn = knn_grid.best_estimator_\n",
        "print(f\"Best parameters: {knn_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating KNN:\")\n",
        "knn_metrics = evaluate_model(best_knn, X_test, y_test)"
      ],
      "metadata": {
        "id": "Jzovn0uWf7cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Radius Neighbors Classifier**"
      ],
      "metadata": {
        "id": "zJ7vYxbGgF2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import RadiusNeighborsClassifier\n",
        "\n",
        "rnc = RadiusNeighborsClassifier()\n",
        "param_grid = {\n",
        "    'radius': [1.0, 2.0, 5.0],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "}\n",
        "\n",
        "print(\"Training Radius Neighbors...\")\n",
        "rnc_grid = GridSearchCV(rnc, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "rnc_grid.fit(X_train, y_train)\n",
        "\n",
        "best_rnc = rnc_grid.best_estimator_\n",
        "print(f\"Best parameters: {rnc_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating Radius Neighbors:\")\n",
        "rnc_metrics = evaluate_model(best_rnc, X_test, y_test)"
      ],
      "metadata": {
        "id": "00TBAYWmgBAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nearest Centroid**"
      ],
      "metadata": {
        "id": "5A7JdXCWgNB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestCentroid\n",
        "\n",
        "nc = NearestCentroid()\n",
        "param_grid = {\n",
        "    'metric': ['euclidean', 'manhattan', 'cosine'],\n",
        "    'shrink_threshold': [None, 0.1, 0.5, 1.0]\n",
        "}\n",
        "\n",
        "print(\"Training Nearest Centroid...\")\n",
        "nc_grid = GridSearchCV(nc, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "nc_grid.fit(X_train, y_train)\n",
        "\n",
        "best_nc = nc_grid.best_estimator_\n",
        "print(f\"Best parameters: {nc_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating Nearest Centroid:\")\n",
        "nc_metrics = evaluate_model(best_nc, X_test, y_test)"
      ],
      "metadata": {
        "id": "R2iEkWj3gJA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MLP Classifier**"
      ],
      "metadata": {
        "id": "2f4aZvkTgTFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(random_state=42, early_stopping=True)\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
        "    'activation': ['relu', 'tanh', 'logistic'],\n",
        "    'alpha': [0.0001, 0.001, 0.01],\n",
        "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
        "    'learning_rate_init': [0.001, 0.01]\n",
        "}\n",
        "\n",
        "print(\"Training MLP...\")\n",
        "mlp_grid = GridSearchCV(mlp, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "mlp_grid.fit(X_train, y_train)\n",
        "\n",
        "best_mlp = mlp_grid.best_estimator_\n",
        "print(f\"Best parameters: {mlp_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating MLP:\")\n",
        "mlp_metrics = evaluate_model(best_mlp, X_test, y_test)"
      ],
      "metadata": {
        "id": "-VV1KFEPgPJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gaussian Process Classifier**"
      ],
      "metadata": {
        "id": "D9O6p7xJgYj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "\n",
        "gpc = GaussianProcessClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'kernel': [None, 'RBF', 'DotProduct'],\n",
        "    'max_iter_predict': [100, 200]\n",
        "}\n",
        "\n",
        "print(\"Training Gaussian Process...\")\n",
        "gpc_grid = GridSearchCV(gpc, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "gpc_grid.fit(X_train, y_train)\n",
        "\n",
        "best_gpc = gpc_grid.best_estimator_\n",
        "print(f\"Best parameters: {gpc_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating Gaussian Process:\")\n",
        "gpc_metrics = evaluate_model(best_gpc, X_test, y_test)"
      ],
      "metadata": {
        "id": "S1i27fo2gVKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Label Propagation**"
      ],
      "metadata": {
        "id": "gJ58kRfWgj9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.semi_supervised import LabelPropagation\n",
        "\n",
        "lp = LabelPropagation()\n",
        "param_grid = {\n",
        "    'kernel': ['rbf', 'knn'],\n",
        "    'gamma': [0.1, 0.5, 1.0],\n",
        "    'n_neighbors': [3, 5, 7]\n",
        "}\n",
        "\n",
        "print(\"Training Label Propagation...\")\n",
        "lp_grid = GridSearchCV(lp, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "lp_grid.fit(X_train, y_train)\n",
        "\n",
        "best_lp = lp_grid.best_estimator_\n",
        "print(f\"Best parameters: {lp_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating Label Propagation:\")\n",
        "lp_metrics = evaluate_model(best_lp, X_test, y_test)"
      ],
      "metadata": {
        "id": "SgvnilhMgdRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Label Spreading**"
      ],
      "metadata": {
        "id": "iKbEH-dCgp48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.semi_supervised import LabelSpreading\n",
        "\n",
        "ls = LabelSpreading()\n",
        "param_grid = {\n",
        "    'kernel': ['rbf', 'knn'],\n",
        "    'alpha': [0.1, 0.5, 0.9],\n",
        "    'n_neighbors': [3, 5, 7]\n",
        "}\n",
        "\n",
        "print(\"Training Label Spreading...\")\n",
        "ls_grid = GridSearchCV(ls, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "ls_grid.fit(X_train, y_train)\n",
        "\n",
        "best_ls = ls_grid.best_estimator_\n",
        "print(f\"Best parameters: {ls_grid.best_params_}\")\n",
        "\n",
        "print(\"\\nEvaluating Label Spreading:\")\n",
        "ls_metrics = evaluate_model(best_ls, X_test, y_test)"
      ],
      "metadata": {
        "id": "_wkbjtKtgmu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Comparison**"
      ],
      "metadata": {
        "id": "7NxCMifcg12s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect all metrics\n",
        "all_metrics = [\n",
        "    log_reg_metrics, ridge_metrics, sgd_metrics,\n",
        "    dt_metrics, rf_metrics, et_metrics,\n",
        "    gb_metrics, xgb_metrics, lgbm_metrics,\n",
        "    cb_metrics, ada_metrics, hgb_metrics,\n",
        "    svc_metrics, linear_svc_metrics, nu_svc_metrics,\n",
        "    gnb_metrics, bnb_metrics, mnb_metrics, cnb_metrics,\n",
        "    lda_metrics, qda_metrics,\n",
        "    knn_metrics, rnc_metrics, nc_metrics,\n",
        "    mlp_metrics,\n",
        "    gpc_metrics,\n",
        "    lp_metrics, ls_metrics\n",
        "]\n",
        "\n",
        "# Create comparison DataFrame\n",
        "results_df = pd.DataFrame([{\n",
        "    'Model': m['model'],\n",
        "    'Accuracy': m['accuracy'],\n",
        "    'Precision': m['classification_report']['weighted avg']['precision'],\n",
        "    'Recall': m['classification_report']['weighted avg']['recall'],\n",
        "    'F1-Score': m['classification_report']['weighted avg']['f1-score']\n",
        "} for m in all_metrics])\n",
        "\n",
        "# Sort by accuracy\n",
        "results_df = results_df.sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nModel Comparison by Accuracy:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "AsoZOLQLgt_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ampob4K_g5Ql"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}