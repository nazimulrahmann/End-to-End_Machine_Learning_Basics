{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPM8IAUTq5nrRpm+dfyeO4J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nazimulrahmann/machine_learning/blob/main/regression_algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kSHP5iHT58Di"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Parameters\n",
        "n_samples = 1000  # Total number of samples\n",
        "n_features = 5    # Number of features\n",
        "noise_level = 2.0 # Amount of noise to add\n",
        "\n",
        "# Generate random features (X) - normally distributed\n",
        "X = np.random.randn(n_samples, n_features)\n",
        "\n",
        "# Create meaningful coefficients for the regression\n",
        "true_coefficients = np.random.randn(n_features) * 3\n",
        "true_intercept = 2.5\n",
        "\n",
        "# Generate target values (y) with linear relationship plus noise\n",
        "y = X @ true_coefficients + true_intercept + np.random.randn(n_samples) * noise_level\n",
        "\n",
        "# Add some non-linear relationships to make it more interesting\n",
        "y += 0.5 * (X[:, 0] ** 2)  # Quadratic term for first feature\n",
        "y += 0.8 * np.sin(X[:, 1])  # Non-linear term for second feature\n",
        "\n",
        "# Split into training and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_regression(model, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Evaluate a regression model and print metrics\n",
        "    Returns a dictionary of metrics\n",
        "    \"\"\"\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred) * 100\n",
        "\n",
        "    # Print results\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"MSE: {mse:.4f}\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "    print(f\"R²: {r2:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'model': str(model),\n",
        "        'mae': mae,\n",
        "        'mse': mse,\n",
        "        'rmse': rmse,\n",
        "        'r2': r2\n",
        "    }"
      ],
      "metadata": {
        "id": "xttduQKe94gl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E8HBCk5K94Nl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Initialize model\n",
        "linear_reg = LinearRegression()\n",
        "\n",
        "# Parameter grid\n",
        "param_grid = {\n",
        "    'fit_intercept': [True, False],\n",
        "    'positive': [True, False]\n",
        "}\n",
        "\n",
        "# Grid search\n",
        "linear_grid = GridSearchCV(linear_reg, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "linear_grid.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_linear = linear_grid.best_estimator_\n",
        "print(f\"Best parameters: {linear_grid.best_params_}\")\n",
        "\n",
        "# Evaluation\n",
        "y_pred = best_linear.predict(X_test)\n",
        "print(\"Linear Regression Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "ap_yMed961MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge = Ridge(random_state=42)\n",
        "param_grid = {\n",
        "    'alpha': [0.1, 0.5, 1.0, 2.0, 5.0],\n",
        "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
        "}\n",
        "\n",
        "ridge_grid = GridSearchCV(ridge, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "ridge_grid.fit(X_train, y_train)\n",
        "\n",
        "best_ridge = ridge_grid.best_estimator_\n",
        "print(f\"Best parameters: {ridge_grid.best_params_}\")\n",
        "\n",
        "y_pred = best_ridge.predict(X_test)\n",
        "print(\"\\nRidge Regression Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFxLoGrR8779",
        "outputId": "88b1e08f-45e0-4531-f13c-d283ecaca3cd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'alpha': 1.0, 'solver': 'sag'}\n",
            "\n",
            "Ridge Regression Evaluation:\n",
            "MAE: 1.6497\n",
            "MSE: 4.3721\n",
            "RMSE: 2.0910\n",
            "R²: 0.8937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "lasso = Lasso(random_state=42)\n",
        "param_grid = {\n",
        "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
        "    'selection': ['cyclic', 'random']\n",
        "}\n",
        "\n",
        "lasso_grid = GridSearchCV(lasso, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "lasso_grid.fit(X_train, y_train)\n",
        "\n",
        "best_lasso = lasso_grid.best_estimator_\n",
        "print(f\"Best parameters: {lasso_grid.best_params_}\")\n",
        "\n",
        "y_pred = best_lasso.predict(X_test)\n",
        "print(\"\\nLasso Regression Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyE6wlv--K6K",
        "outputId": "3103e321-450f-4dee-d5af-cae480de50eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'alpha': 0.0001, 'selection': 'random'}\n",
            "\n",
            "Lasso Regression Evaluation:\n",
            "MAE: 1.6497\n",
            "MSE: 4.3726\n",
            "RMSE: 2.0911\n",
            "R²: 0.8937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "elastic = ElasticNet(random_state=42)\n",
        "param_grid = {\n",
        "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
        "    'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
        "    'selection': ['cyclic', 'random']\n",
        "}\n",
        "\n",
        "elastic_grid = GridSearchCV(elastic, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "elastic_grid.fit(X_train, y_train)\n",
        "\n",
        "best_elastic = elastic_grid.best_estimator_\n",
        "print(f\"Best parameters: {elastic_grid.best_params_}\")\n",
        "\n",
        "y_pred = best_elastic.predict(X_test)\n",
        "print(\"\\nElasticNet Regression Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVooawZA-K3E",
        "outputId": "293bcf6e-2274-4dcc-c096-95c5d95a9bfa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'alpha': 0.0001, 'l1_ratio': 0.9, 'selection': 'random'}\n",
            "\n",
            "ElasticNet Regression Evaluation:\n",
            "MAE: 1.6497\n",
            "MSE: 4.3726\n",
            "RMSE: 2.0911\n",
            "R²: 0.8937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "param_grid = {\n",
        "    'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
        "    'max_depth': [None, 5, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "dt_grid = GridSearchCV(dt, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "dt_grid.fit(X_train, y_train)\n",
        "\n",
        "best_dt = dt_grid.best_estimator_\n",
        "print(f\"Best parameters: {dt_grid.best_params_}\")\n",
        "\n",
        "y_pred = best_dt.predict(X_test)\n",
        "print(\"\\nDecision Tree Regressor Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "5uRPuBtA-K0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "rf_grid = GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "rf_grid.fit(X_train, y_train)\n",
        "\n",
        "best_rf = rf_grid.best_estimator_\n",
        "print(f\"Best parameters: {rf_grid.best_params_}\")\n",
        "\n",
        "y_pred = best_rf.predict(X_test)\n",
        "print(\"\\nRandom Forest Regressor Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "fwQfGM9y-KxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "gb = GradientBoostingRegressor(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "gb_grid = GridSearchCV(gb, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "gb_grid.fit(X_train, y_train)\n",
        "\n",
        "best_gb = gb_grid.best_estimator_\n",
        "print(f\"Best parameters: {gb_grid.best_params_}\")\n",
        "\n",
        "y_pred = best_gb.predict(X_test)\n",
        "print(\"\\nGradient Boosting Regressor Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "ZM-5OBHS-KuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "svr = SVR()\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "    'gamma': ['scale', 'auto', 0.1, 1],\n",
        "    'degree': [2, 3, 4],\n",
        "    'epsilon': [0.01, 0.1, 0.5]\n",
        "}\n",
        "\n",
        "svr_grid = GridSearchCV(svr, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "svr_grid.fit(X_train, y_train)\n",
        "\n",
        "best_svr = svr_grid.best_estimator_\n",
        "print(f\"Best parameters: {svr_grid.best_params_}\")\n",
        "\n",
        "y_pred = best_svr.predict(X_test)\n",
        "print(\"\\nSupport Vector Regressor Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "RszVlpwA-Kq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "xgb = XGBRegressor(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2],\n",
        "    'reg_alpha': [0, 0.1, 1],\n",
        "    'reg_lambda': [0, 0.1, 1]\n",
        "}\n",
        "\n",
        "xgb_grid = GridSearchCV(xgb, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "xgb_grid.fit(X_train, y_train)\n",
        "\n",
        "best_xgb = xgb_grid.best_estimator_\n",
        "print(f\"Best parameters: {xgb_grid.best_params_}\")\n",
        "\n",
        "y_pred = best_xgb.predict(X_test)\n",
        "print(\"\\nXGBoost Regressor Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "DjdUHAVq-e-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "lgbm = LGBMRegressor(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'num_leaves': [31, 63, 127],\n",
        "    'max_depth': [-1, 10, 20],\n",
        "    'min_child_samples': [20, 50],\n",
        "    'reg_alpha': [0, 0.1, 1],\n",
        "    'reg_lambda': [0, 0.1, 1]\n",
        "}\n",
        "\n",
        "lgbm_grid = GridSearchCV(lgbm, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "lgbm_grid.fit(X_train, y_train)\n",
        "\n",
        "best_lgbm = lgbm_grid.best_estimator_\n",
        "print(f\"Best parameters: {lgbm_grid.best_params_}\")\n",
        "\n",
        "y_pred = best_lgbm.predict(X_test)\n",
        "print(\"\\nLightGBM Regressor Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "blzeWl0a-fBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostRegressor\n",
        "\n",
        "cat = CatBoostRegressor(random_state=42, verbose=0)\n",
        "param_grid = {\n",
        "    'iterations': [100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'depth': [4, 6, 8],\n",
        "    'l2_leaf_reg': [1, 3, 5]\n",
        "}\n",
        "\n",
        "cat_grid = GridSearchCV(cat, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "cat_grid.fit(X_train, y_train)\n",
        "\n",
        "best_cat = cat_grid.best_estimator_\n",
        "print(f\"Best parameters: {cat_grid.best_params_}\")\n",
        "\n",
        "y_pred = best_cat.predict(X_test)\n",
        "print(\"\\nCatBoost Regressor Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "578j-vr6-fEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "mlp = MLPRegressor(random_state=42, early_stopping=True)\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
        "    'activation': ['relu', 'tanh', 'logistic'],\n",
        "    'alpha': [0.0001, 0.001, 0.01],\n",
        "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
        "    'learning_rate_init': [0.001, 0.01]\n",
        "}\n",
        "\n",
        "mlp_grid = GridSearchCV(mlp, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "mlp_grid.fit(X_train, y_train)\n",
        "\n",
        "best_mlp = mlp_grid.best_estimator_\n",
        "print(f\"Best parameters: {mlp_grid.best_params_}\")\n",
        "\n",
        "y_pred = best_mlp.predict(X_test)\n",
        "print(\"\\nMLP Regressor Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "qRIyfVba-fHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import BayesianRidge\n",
        "\n",
        "bayesian = BayesianRidge()\n",
        "param_grid = {\n",
        "    'alpha_1': [1e-6, 1e-5, 1e-4],\n",
        "    'alpha_2': [1e-6, 1e-5, 1e-4],\n",
        "    'lambda_1': [1e-6, 1e-5, 1e-4],\n",
        "    'lambda_2': [1e-6, 1e-5, 1e-4]\n",
        "}\n",
        "\n",
        "bayesian_grid = GridSearchCV(bayesian, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "bayesian_grid.fit(X_train, y_train)\n",
        "\n",
        "best_bayesian = bayesian_grid.best_estimator_\n",
        "print(f\"Best parameters: {bayesian_grid.best_params_}\")\n",
        "\n",
        "y_pred = best_bayesian.predict(X_test)\n",
        "print(\"\\nBayesian Ridge Regression Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "u3B_1Sfq-fK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel\n",
        "\n",
        "kernel = ConstantKernel() * RBF()\n",
        "gp = GaussianProcessRegressor(kernel=kernel, random_state=42)\n",
        "param_grid = {\n",
        "    'alpha': [1e-10, 1e-5, 1e-2],\n",
        "    'normalize_y': [True, False]\n",
        "}\n",
        "\n",
        "gp_grid = GridSearchCV(gp, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "gp_grid.fit(X_train, y_train)\n",
        "\n",
        "best_gp = gp_grid.best_estimator_\n",
        "print(f\"Best parameters: {gp_grid.best_params_}\")\n",
        "\n",
        "y_pred = best_gp.predict(X_test)\n",
        "print(\"\\nGaussian Process Regressor Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "m8P9-05D-fOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "knn = KNeighborsRegressor()\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "    'p': [1, 2]\n",
        "}\n",
        "\n",
        "knn_grid = GridSearchCV(knn, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "knn_grid.fit(X_train, y_train)\n",
        "\n",
        "best_knn = knn_grid.best_estimator_\n",
        "print(f\"Best parameters: {knn_grid.best_params_}\")\n",
        "\n",
        "y_pred = best_knn.predict(X_test)\n",
        "print(\"\\nK-Nearest Neighbors Regressor Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "9y4sX-zb-fRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "\n",
        "ada = AdaBoostRegressor(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 1.0],\n",
        "    'loss': ['linear', 'square', 'exponential']\n",
        "}\n",
        "\n",
        "ada_grid = GridSearchCV(ada, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "ada_grid.fit(X_train, y_train)\n",
        "\n",
        "best_ada = ada_grid.best_estimator_\n",
        "print(f\"Best parameters: {ada_grid.best_params_}\")\n",
        "\n",
        "y_pred = best_ada.predict(X_test)\n",
        "print(\"\\nAdaBoost Regressor Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "DO99ExQQ-fVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import BayesianRidge\n",
        "\n",
        "# Initialize model\n",
        "bayesian = BayesianRidge()\n",
        "\n",
        "# Parameter grid\n",
        "param_grid = {\n",
        "    'alpha_1': [1e-6, 1e-5, 1e-4],\n",
        "    'alpha_2': [1e-6, 1e-5, 1e-4],\n",
        "    'lambda_1': [1e-6, 1e-5, 1e-4],\n",
        "    'lambda_2': [1e-6, 1e-5, 1e-4]\n",
        "}\n",
        "\n",
        "# Grid search\n",
        "print(\"Training Bayesian Ridge Regression...\")\n",
        "bayesian_grid = GridSearchCV(bayesian, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "bayesian_grid.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_bayesian = bayesian_grid.best_estimator_\n",
        "print(f\"Best parameters: {bayesian_grid.best_params_}\")\n",
        "\n",
        "# Evaluation\n",
        "y_pred = best_bayesian.predict(X_test)\n",
        "print(\"\\nBayesian Ridge Regression Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "-C6YqJOy-fYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "\n",
        "# Initialize model\n",
        "sgd = SGDRegressor(random_state=42)\n",
        "\n",
        "# Parameter grid\n",
        "param_grid = {\n",
        "    'loss': ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
        "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
        "    'alpha': [0.0001, 0.001, 0.01],\n",
        "    'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
        "    'eta0': [0.01, 0.1]  # Initial learning rate\n",
        "}\n",
        "\n",
        "# Grid search\n",
        "print(\"Training SGD Regressor...\")\n",
        "sgd_grid = GridSearchCV(sgd, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "sgd_grid.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_sgd = sgd_grid.best_estimator_\n",
        "print(f\"Best parameters: {sgd_grid.best_params_}\")\n",
        "\n",
        "# Evaluation\n",
        "y_pred = best_sgd.predict(X_test)\n",
        "print(\"\\nSGD Regressor Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "s8p9l7x6-fbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import HuberRegressor\n",
        "\n",
        "# Initialize model\n",
        "huber = HuberRegressor()\n",
        "\n",
        "# Parameter grid\n",
        "param_grid = {\n",
        "    'epsilon': [1.1, 1.35, 1.5],  # Threshold for outliers\n",
        "    'alpha': [0.0001, 0.001, 0.01],  # Regularization strength\n",
        "    'max_iter': [100, 200, 300]  # Maximum iterations\n",
        "}\n",
        "\n",
        "# Grid search\n",
        "print(\"Training Huber Regressor...\")\n",
        "huber_grid = GridSearchCV(huber, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "huber_grid.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_huber = huber_grid.best_estimator_\n",
        "print(f\"Best parameters: {huber_grid.best_params_}\")\n",
        "\n",
        "# Evaluation\n",
        "y_pred = best_huber.predict(X_test)\n",
        "print(\"\\nHuber Regressor Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "mq85-Xvz-fe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import TheilSenRegressor\n",
        "\n",
        "# Initialize model\n",
        "theil = TheilSenRegressor(random_state=42)\n",
        "\n",
        "# Parameter grid\n",
        "param_grid = {\n",
        "    'max_subpopulation': [1000, 5000, 10000],  # Max subsets considered\n",
        "    'n_subsamples': [None, 100, 200],  # Number of samples per subset\n",
        "    'max_iter': [100, 300, 500]  # Maximum iterations\n",
        "}\n",
        "\n",
        "# Grid search\n",
        "print(\"Training Theil-Sen Regressor...\")\n",
        "theil_grid = GridSearchCV(theil, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "theil_grid.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_theil = theil_grid.best_estimator_\n",
        "print(f\"Best parameters: {theil_grid.best_params_}\")\n",
        "\n",
        "# Evaluation\n",
        "y_pred = best_theil.predict(X_test)\n",
        "print(\"\\nTheil-Sen Regressor Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "Dsq2YU7H-fiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import RANSACRegressor\n",
        "\n",
        "# Initialize base estimator (using LinearRegression as default)\n",
        "base_estimator = LinearRegression()\n",
        "\n",
        "# Initialize RANSAC model\n",
        "ransac = RANSACRegressor(base_estimator=base_estimator, random_state=42)\n",
        "\n",
        "# Parameter grid\n",
        "param_grid = {\n",
        "    'min_samples': [None, 0.1, 0.5, 0.9],  # Min samples to fit\n",
        "    'residual_threshold': [None, 1.0, 2.0],  # Threshold for inliers\n",
        "    'max_trials': [50, 100, 200],  # Max iterations\n",
        "    'stop_probability': [0.95, 0.99]  # Probability to stop\n",
        "}\n",
        "\n",
        "# Grid search\n",
        "print(\"Training RANSAC Regressor...\")\n",
        "ransac_grid = GridSearchCV(ransac, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "ransac_grid.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_ransac = ransac_grid.best_estimator_\n",
        "print(f\"Best parameters: {ransac_grid.best_params_}\")\n",
        "\n",
        "# Evaluation\n",
        "y_pred = best_ransac.predict(X_test)\n",
        "print(\"\\nRANSAC Regressor Evaluation:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "3uf8Cn2BRBVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect all metrics (add all model metrics here)\n",
        "all_metrics = [\n",
        "    {'model': 'Linear Regression', **linear_metrics},\n",
        "    {'model': 'Ridge Regression', **ridge_metrics},\n",
        "    {'model': 'Lasso Regression', **lasso_metrics},\n",
        "    {'model': 'ElasticNet', **elastic_metrics},\n",
        "    {'model': 'Decision Tree', **dt_metrics},\n",
        "    {'model': 'Random Forest', **rf_metrics},\n",
        "    {'model': 'Gradient Boosting', **gb_metrics},\n",
        "    {'model': 'XGBoost', **xgb_metrics},\n",
        "    {'model': 'LightGBM', **lgbm_metrics},\n",
        "    {'model': 'CatBoost', **cat_metrics},\n",
        "    {'model': 'SVR', **svr_metrics},\n",
        "    {'model': 'MLP', **mlp_metrics},\n",
        "    {'model': 'Bayesian Ridge', **bayesian_metrics},\n",
        "    {'model': 'Gaussian Process', **gp_metrics},\n",
        "    {'model': 'KNN', **knn_metrics},\n",
        "    {'model': 'AdaBoost', **ada_metrics},\n",
        "    {'model': 'Bayesian Ridge', **bayesian_metrics},\n",
        "    {'model': 'SGD Regressor', **sgd_metrics},\n",
        "    {'model': 'Huber Regressor', **huber_metrics},\n",
        "    {'model': 'Theil-Sen Regressor', **theil_metrics},\n",
        "    {'model': 'RANSAC Regressor', **ransac_metrics}\n",
        "]\n",
        "\n",
        "# Create DataFrame\n",
        "results_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "# Sort by RMSE (lower is better)\n",
        "results_df = results_df.sort_values('RMSE').reset_index(drop=True)\n",
        "\n",
        "print(\"\\nFinal Model Comparison:\")\n",
        "print(results_df[['model', 'RMSE', 'R²', 'MAE', 'MSE']])"
      ],
      "metadata": {
        "id": "z0IedGqpRBR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PwcOyTryRBN7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}